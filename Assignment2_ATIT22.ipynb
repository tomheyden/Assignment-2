{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "42db2df048a857b67bc17d304ffcdd40dce6b5ec7644d3f3f3a44d8704f16b2a"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('py36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ_cxSNSKNZy"
      },
      "source": [
        "# Assignment 2\n",
        "Group assignment with groups of 3-4 people. (30 points in total)\n",
        "\n",
        "This assignment will focus on multi class classifaction problems.\n",
        "There are three different techniques which should be applied:\n",
        "\n",
        "*   Softmax Regression (Multi-Class Logist Regression)\n",
        "*   Decision Tree Classifier\n",
        "*   KNN Classifier (& Logistic Regression)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80klRBfiLAsx"
      },
      "source": [
        "## Part 1: Softmax Regression\n",
        "\n",
        "(5 points)\n",
        "\n",
        "Your task is to train a softmax regression model on the MNIST dataset to classify images of handwritten digits from 0 to 9.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_3HJX8NJgOK"
      },
      "source": [
        "# load required libraries\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17fp1eGMNem1"
      },
      "source": [
        "The task will be to perform classification on handwritten digits from 0 to 9 (MNIST dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy1EnttQLwbt"
      },
      "source": [
        "# download dataset from https://www.openml.org/ which contains many sample datasets for machine learning\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypnZn2uKOFME"
      },
      "source": [
        "The dataset contains 70000 examples of which each example has 784 values (pixels). These pixels are in a flat array but represent a 28 by 28 pixel gray-scale image. Values range from 0 to 255 which is common in the RGB value range. A value of 0 represents a black pixel whereas 255 represents a white pixel. Different shades of gray are any value larger than 0 but smaller than 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SY3LIc6PyoC"
      },
      "source": [
        "### Data exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSKanQQ47PIO"
      },
      "source": [
        "Look at some examples of handwritten digits in the dataset to familiarize yourself with the data you want to train the model on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoX0Iwn3M1lY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9_ekBSEPuWe"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GEwEfQjN3u9"
      },
      "source": [
        "Perform a train test split using sklearn.model_selection.train_test_split (as it was done in the previous assignment)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpjdJZ4GNF88"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNLFnY9uQNTR"
      },
      "source": [
        "Do feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5UrcopaQNfo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQYgHy3pOgh"
      },
      "source": [
        "Is feature scaling actually necessary in this case? Please elaborate why or why not:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCbXADZepTe1"
      },
      "source": [
        "**--> Your answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwBhxSsCP69c"
      },
      "source": [
        "### Training the models\n",
        "\n",
        "Please use LogisticRegression from sklearn.linear_model. When initialising the LogisticRegression model please set the parameter \"multi_class\" to \"multinomial\" to make sure your LogisticRegression model perform a multiclass classification instead of a binary classification. More information here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJuyyq0nOAvS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-2ST4d1P-nF"
      },
      "source": [
        "### Evaluating model performance\n",
        "\n",
        "Please analyze the model accuracy and plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dvb6U9rQBgD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB3aYs2PhjPw"
      },
      "source": [
        "Based on the confusion matrix, where do you expect the model to make good decisions? Where is the classification shaky?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqWAy47ihxFL"
      },
      "source": [
        "**---> Your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpgLYAcphX9n"
      },
      "source": [
        "### Visualizing what the model has learned\n",
        "\n",
        "Use the following code to visualize the coefficients the trained model has learned.\n",
        "You simply need to replace the <<model>> placeholder with the variable name of your trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRkED_wthze2"
      },
      "source": [
        "coef = <<model>>.coef_.copy()\n",
        "scale = np.abs(coef).max()\n",
        "plt.figure(figsize=(13,7))\n",
        "\n",
        "for i in range(10): # 0-9\n",
        "    coef_plot = plt.subplot(2, 5, i + 1) # 2x5 plot\n",
        "\n",
        "    coef_plot.imshow(coef[i].reshape(28,28), \n",
        "                     cmap=plt.cm.RdBu,\n",
        "                     vmin=-scale, vmax=scale,\n",
        "                    interpolation='bilinear')\n",
        "    \n",
        "    coef_plot.set_xticks(()); coef_plot.set_yticks(())\n",
        "    coef_plot.set_xlabel(f'Class {i}')\n",
        "\n",
        "plt.suptitle('Coefficients for various classes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t1hGDICjNsT"
      },
      "source": [
        "Try to explain briefly what the coefficients tell you about how the model differentiate the different classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXnOxjY6jbAH"
      },
      "source": [
        "**--> your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztHRoT9qY896"
      },
      "source": [
        "Plot some examples of missclassified numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfldkBI5Y896"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fDSuPFGTUIP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Part 2: Decission Tree Classifier\n",
        "\n",
        "(5 points)\n",
        "\n",
        "Your task is to train a decision tree classifier on the heart disease dataset from the UCI Machine Learning repository [https://archive.ics.uci.edu/ml/datasets/abalone. ](https://archive.ics.uci.edu/ml/datasets/heart+disease)\n",
        "\n",
        "Your task is to decide if a person has a heart disease based on some other attributes.\n",
        "Target class has two vales:\n",
        "- 0 : no heart disease (healthy)\n",
        "- 1 : heart disease\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCbUUPcwTcmZ"
      },
      "source": [
        "# load required libraries\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# download data set\n",
        "dtdf = pd.read_csv('https://github.com/schneiderson/ATIT2-21/raw/master/sample_data/heart.csv', sep=\",\")\n",
        "X=dtdf.iloc[:,:-1]\n",
        "y=dtdf.iloc[:, -1].values.reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_je2b8RRTZo5"
      },
      "source": [
        "### Data exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytuUT8RyTtGe"
      },
      "source": [
        "Familiarize yourself with the dataset. Look at the different features available for making a classification decision. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7o4GL51TsYO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFqq_ydGVRBW"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aN_Z116qhk"
      },
      "source": [
        "Perform a train test split using sklearn.model_selection.train_test_split (as it was done in the previous assignment).\n",
        "Since the dataset doesn't cotain that many instances, leave 40% of the data as a test set and 60% for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRzQF8ulTW4N"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkGfeqwIzrhr"
      },
      "source": [
        "Do feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL90xNQzzusv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ypSNWdWzzGT"
      },
      "source": [
        "Is feature scaling actually necessary in this case? Please elaborate why or why not:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEmw4VDhz1On"
      },
      "source": [
        "**--> your answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrH__FlbVUG3"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "\n",
        "Train the decision tree model on your training data. Use the DecisionTreeClassifier class from the sklearn.tree package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLSw3qmKVWz1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRhAdlSwVXYD"
      },
      "source": [
        "### Evaluating model performance\n",
        "\n",
        "Please evaluate the model performance based on its accuracy score and the confusion matrix on the test-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFtDOxot86Al"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhxz0ucn867C"
      },
      "source": [
        "### Visualizing the decision tree\n",
        "\n",
        "To learn how to plot a trained decision tree, please refer to the notebook https://github.com/schneiderson/ATIT2-21/blob/master/intro/DecisionTreeClassifierExample.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Kxjtj99GcR"
      },
      "source": [
        "### Regularization\n",
        "\n",
        "Use the \"max_depth\" parameter, train the decision tree for values [1, 3, 5, 7] and plot the corresponding training and test accuracies.\n",
        "\n",
        "Afterwards, use the \"max_leaf_nodes\" parameter (not using the \"max_depth\" parameter) for the values of [2, 4, 10] and plot the corresponding training and test accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMGzAPEK8-uO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrx_fQxgTXfT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Part 3: KNN Classifier\n",
        "\n",
        "(20 Points)\n",
        "\n",
        "### Adult income dataset\n",
        "\n",
        "This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). The prediction task is to determine whether a person makes over $50K a year.\n",
        "\n",
        "More information about the dataset can be found here: http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsz4WTMbTZCt"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, plot_roc_curve, roc_curve, roc_auc_score, confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dtdf = pd.read_csv('https://raw.githubusercontent.com/schneiderson/ATIT2-22/main/sample_data/adult.csv', sep=\",\")\n",
        "X=dtdf.iloc[:,:-1]\n",
        "y=dtdf.iloc[:, -1].values.reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faEk8welVc0S"
      },
      "source": [
        "### Data Exploration\n",
        "\n",
        "Familiarize yourself with the dataset. Take a look at the class distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Fey-ioT2xY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dnYEdTcY898"
      },
      "source": [
        "Do some features have strange values?\n",
        "If yes, could it be problematic during training and how could you deal with those values?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYMF7nZCY898"
      },
      "source": [
        "**--> your answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2bkh7aNVerB"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do label encooding on the target variable and on independent variables."
      ],
      "metadata": {
        "id": "4cb5k8tLmunR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BiWp8x5Dmu2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmd2YYiH60mT"
      },
      "source": [
        "Perform a train test split using sklearn.model_selection.train_test_split (as it was done in the previous assignment). Leave 20% of the data as a test set and 80% for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THVs3vWuVhZJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIqJaI4W62Ze"
      },
      "source": [
        "Do feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVbZ_UCX62x4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USO2QrjYCgwc"
      },
      "source": [
        "Is feature scaling actually necessary in this case? Please elaborate why or why not:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PydOdInPCh7B"
      },
      "source": [
        "**--> your answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Wj8f_5ViBL"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfb1w-tNVkbt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81i2GaAVle4"
      },
      "source": [
        "### Evaluating model performance\n",
        "\n",
        "Evaluate the model performance using the classification accuracy. Also plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbiELO2XVnx5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMCgtvf4JivU"
      },
      "source": [
        "### Regularization\n",
        "\n",
        "Train the KNN model with different values for K [1, 3, 5, 8, 10].\n",
        "Compare and plot the training and test accuracy of the KNN classifier for each value of k."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4b-J5MjpVem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pick the model K which achieved the highest accuracy. Use the plot_roc_curve function to plot the ROC curve for the model with value K which achieved the highest accuracy."
      ],
      "metadata": {
        "id": "XPGpu1rgofwt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re0BrD3OJxdH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "41Cx32QQnACL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a logistic regression model on the same dataset and compare the performance "
      ],
      "metadata": {
        "id": "wVLx5uuRnFkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous assignment you have used a logistic regression model for classification. Try to train a logistic regression model on current dataset and compare the performance with the KNN classifier."
      ],
      "metadata": {
        "id": "JPMEmb04pgcW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FmxmmzC-nBBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create accuracy score, confusion matrix and ROC curve for the logistic regression classifier. Compare the metrics with the metrics of the KNN model."
      ],
      "metadata": {
        "id": "CROVGUgkoniQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jhry5KVpW_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}